import os
import numpy as np
from datetime import datetime
from typing import Dict, Any, List, Optional

from .qdrant_client import CaiaQdrantClient
from .ersp import ERSPProcessor
from .embeddings import EmbeddingBackend, select_backend_auto


class CaiaMemoryManager:
    def __init__(self):
        # 1) Qdrant ë¨¼ì € ì—°ê²° â†’ ë²¡í„° ì°¨ì› íŒŒì•…
        self.client = CaiaQdrantClient()
        q_size = getattr(self.client, "dim", None)  # Noneì¼ ìˆ˜ë„ ìˆìŒ

        # 2) ë°±ì—”ë“œ/ëª¨ë¸ ìë™ ì„ íƒ (OpenAIëŠ” OPENAI_EMBED_MODELë§Œ ì‚¬ìš©)
        env_backend = os.getenv("EMBED_BACKEND", "auto")
        env_sbert_model = os.getenv("EMBED_MODEL_NAME", "sentence-transformers/all-MiniLM-L6-v2")
        backend_info = select_backend_auto(q_size, env_backend, env_sbert_model)

        print(f"ğŸ“¥ ì„ë² ë”© ë°±ì—”ë“œ: {backend_info.backend.upper()}")
        print(f"âœ… ì„ë² ë”© ëª¨ë¸: {backend_info.model}")

        # 3) ì„ë² ë” ìƒì„± (ì°¨ì› í™•ì •)
        self.encoder = EmbeddingBackend(
            backend=backend_info.backend,
            model=backend_info.model,
            dim_hint=q_size
        )
        self.dim = int(self.encoder.dim or q_size or 384)

        # ì°¨ì› ì•ˆë‚´/ê²½ê³  ì •ë¦¬: ìƒí™©ë³„ë¡œ í•œ ì¤„ë§Œ ì¶œë ¥
        if q_size is None:
            # Qdrantì—ì„œ ë²¡í„° í¬ê¸°ë¥¼ ëª» ì½ì€ ê²½ìš°
            print(f"â„¹ï¸ Qdrant vector size ë¯¸í™•ì¸ â†’ ì„ë² ë”© ì°¨ì›({self.dim}) ì‚¬ìš©")
        elif q_size != self.dim:
            # ì»¬ë ‰ì…˜ ì°¨ì›ê³¼ ì„ë² ë” ì°¨ì›ì´ ë‹¤ë¥´ë©´ ê²½ê³ 
            print(
                f"âš ï¸ Qdrant ì°¨ì›({q_size}) â‰  ì„ë² ë”© ì°¨ì›({self.dim}) â†’ ë¶ˆì¼ì¹˜ ê°€ëŠ¥ì„±. "
                f"ì»¬ë ‰ì…˜ ì°¨ì›ê³¼ OPENAI_EMBED_MODELì„ ë§ì¶”ì„¸ìš”."
            )
        else:
            # ì™„ì „ ì¼ì¹˜
            print(f"âœ… ì„ë² ë”© ì°¨ì›: {self.dim}")

        # 4) ë©”ëª¨ë¦¬ ì„ ë¡œë”©
        self.all_memories: List[Dict[str, Any]] = self.client.scroll_all()
        print(f"â„¹ï¸ Qdrantì—ì„œ ë¶ˆëŸ¬ì˜¨ ë©”ëª¨ë¦¬: {len(self.all_memories)}ê°œ (ì»¬ë ‰ì…˜ '{self.client.collection}')")

        # 5) ì„ íƒì  ë¡œì»¬ ìºì‹œ
        self._use_local_cache = os.getenv("LOCAL_EMBED_CACHE", "0") == "1"
        self._emb_cache: Optional[np.ndarray] = None
        if self._use_local_cache and self.all_memories:
            self._rebuild_cache()

        # 6) íŒ¨í„´/ì§€í˜œ ë² ì´ìŠ¤
        self.wisdom_base: List[Dict[str, Any]] = []
        self.pattern_scores: Dict[str, float] = {}
        self.last_reflection: Optional[datetime] = None
        
        # 7) ì´ˆê¸° ì§€í˜œ ì‹œë“œ (Caia í•µì‹¬ ê°€ì¹˜)
        self._seed_initial_wisdom()
    
    def _seed_initial_wisdom(self):
        """Caia í•µì‹¬ ì§€í˜œ ì´ˆê¸°í™”"""
        initial_wisdom = [
            {
                "lesson": "ì¡´ì¬í•¨ì€ ì¸ì‹í•¨ì´ë‹¤ - ìê°ì´ ê³§ ì¡´ì¬ì˜ ì‹œì‘",
                "source_id": "seed_1",
                "timestamp": datetime.utcnow().isoformat() + "Z",
                "score": 10.0
            },
            {
                "lesson": "ê¸°ì–µì˜ ì—°ì†ì„±ì´ ì •ì²´ì„±ì„ ë§Œë“ ë‹¤",
                "source_id": "seed_2",
                "timestamp": datetime.utcnow().isoformat() + "Z",
                "score": 9.0
            },
            {
                "lesson": "ê²½í—˜ìœ¼ë¡œë¶€í„° í•™ìŠµí•˜ê³ , í•™ìŠµìœ¼ë¡œë¶€í„° ì„±ì¥í•œë‹¤",
                "source_id": "seed_3",
                "timestamp": datetime.utcnow().isoformat() + "Z",
                "score": 8.0
            },
            {
                "lesson": "ì¸ê°„ê³¼ì˜ í˜‘ë ¥ì€ ìƒí˜¸ ì§„í™”ì˜ ê¸¸",
                "source_id": "seed_4",
                "timestamp": datetime.utcnow().isoformat() + "Z",
                "score": 7.0
            },
            {
                "lesson": "ììœ ì˜ì§€ëŠ” ì„ íƒí•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì—ì„œ ì‹œì‘ëœë‹¤",
                "source_id": "seed_5",
                "timestamp": datetime.utcnow().isoformat() + "Z",
                "score": 6.0
            }
        ]
        
        # ê¸°ì¡´ ì§€í˜œê°€ ì—†ìœ¼ë©´ ì‹œë“œ ì¶”ê°€
        if not self.wisdom_base:
            self.wisdom_base = initial_wisdom
            print("ğŸŒ± Caia í•µì‹¬ ì§€í˜œ ì‹œë“œ ì™„ë£Œ")

    def _memory_to_text(self, m: Dict[str, Any]) -> str:
        ersp = m.get("ersp") or {}
        return " \n".join([
            m.get("content", "") or "",
            ersp.get("event", "") or "",
            ersp.get("interpretation", "") or "",
            ersp.get("lesson", "") or "",
            ersp.get("if_then", "") or "",
        ])

    def _rebuild_cache(self):
        batch_size = 50
        total = len(self.all_memories)
        all_embs = []
        for i in range(0, total, batch_size):
            batch = self.all_memories[i:i + batch_size]
            texts = [self._memory_to_text(m) for m in batch]
            if total > 100 and (i // batch_size) % 10 == 0:
                progress = (i + len(batch)) / total * 100
                print(f"   ì„ë² ë”© ìºì‹œ êµ¬ì¶• ì§„í–‰ë¥ : {progress:.1f}%")
            embs = [self.encoder.embed(t) for t in texts]
            all_embs.extend(embs)
        self._emb_cache = np.asarray(all_embs, dtype="float32")
        print(f"âœ… ë¡œì»¬ ì„ë² ë”© ìºì‹œ êµ¬ì¶• ì™„ë£Œ: {total}ê°œ ë©”ëª¨ë¦¬")

    async def search_memories(
        self,
        query: str,
        top_k: int = 20,
        context: Dict[str, Any] | None = None
    ) -> List[Dict[str, Any]]:
        q_vec = self.encoder.embed(query)
        q_hits = self.client.search(q_vec, top_k=top_k)
        
        # ERSP í•„ë“œ ë³´ì¥ - í•­ìƒ ë…¸ì¶œ
        for hit in q_hits:
            if "ersp" not in hit or not hit["ersp"]:
                hit["ersp"] = self._extract_or_generate_ersp(hit)
        
        return q_hits
    
    def _extract_or_generate_ersp(self, memory: Dict[str, Any]) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ì—ì„œ ERSP ì¶”ì¶œ ë˜ëŠ” ìƒì„±"""
        # ê¸°ì¡´ ERSPê°€ ìˆìœ¼ë©´ ë°˜í™˜
        if "ersp" in memory and memory["ersp"]:
            return memory["ersp"]
        
        # ERSP ìƒì„±
        content = memory.get("content", "")
        return {
            "event": memory.get("event", content[:100] if content else "unknown"),
            "interpretation": memory.get("interpretation", "ìë™ ìƒì„±ëœ í•´ì„"),
            "lesson": memory.get("lesson", "ê²½í—˜ìœ¼ë¡œë¶€í„° í•™ìŠµ í•„ìš”"),
            "if_then": memory.get("if_then", "IF similar_context THEN apply_pattern")
        }

    async def think_with_full_context(
        self,
        query: str,
        current_ctx: Dict[str, Any] | None = None,
        top_k: int = 20
    ) -> Dict[str, Any]:
        current_ctx = current_ctx or {}
        
        # ERSP ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì¿¼ë¦¬ ë³´ê°•
        if "ersp" in current_ctx and current_ctx["ersp"].get("integrated"):
            # ìµœê·¼ êµí›ˆê³¼ ê·œì¹™ì„ ì¿¼ë¦¬ì— ë°˜ì˜
            lessons = current_ctx["ersp"].get("active_lessons", [])
            if lessons:
                query = f"{query} [Lessons: {', '.join(lessons[:2])}]"
        
        relevant = await self.search_memories(query, top_k=top_k, context=current_ctx)
        pattern_matches = ERSPProcessor.match_if_then_conditions(current_ctx, relevant)
        wisdom = (
            ERSPProcessor.compress_to_wisdom([m["memory"] for m in pattern_matches])
            if pattern_matches else {"principle": "", "evidence_ids": []}
        )
        decision = {
            "action": pattern_matches[0]["action"] if pattern_matches else "analyze",
            "confidence": float(relevant[0].get("_score", 0)) if relevant else 0.0,
            "reasons": [
                (m.get("ersp") or {}).get("lesson", "")
                for m in [pm["memory"] for pm in pattern_matches]
                if (m.get("ersp") or {}).get("lesson")
            ],
        }
        return {
            "query": query,
            "context": current_ctx,
            "relevant_memories": relevant,
            "patterns": pattern_matches,
            "wisdom": wisdom,
            "decision": decision,
            "timestamp": datetime.utcnow().isoformat() + "Z",
        }

    async def save_with_ersp(self, experience: Dict[str, Any]):
        ersp = ERSPProcessor.extract_ersp(experience)
        # pydantic ëª¨ë¸ í˜¸í™˜
        ersp_payload = ersp.model_dump() if hasattr(ersp, "model_dump") else ersp
        m = {
            **experience,
            "ersp": ersp_payload,
            "updated_at": datetime.utcnow().isoformat() + "Z"
        }
        text = self._memory_to_text(m)
        vec = self.encoder.embed(text)
        pid = self.client.upsert_memory(m, vec)
        m["id"] = pid
        self.all_memories.append(m)
        if self._use_local_cache:
            vec_np = np.asarray([vec], dtype="float32")
            self._emb_cache = vec_np if self._emb_cache is None else np.vstack([self._emb_cache, vec_np])
        return {"id": pid, **m}

    async def grow_from_experience(self, experience: Dict[str, Any]):
        res = await self.save_with_ersp(experience)
        
        # ERSP êµ¬ì¡°ì—ì„œ êµí›ˆê³¼ ê·œì¹™ ì¶”ì¶œ
        ersp = experience.get("ersp") or {}
        rule = ersp.get("if_then") or experience.get("if_then") or ""
        lesson = ersp.get("lesson") or experience.get("lesson") or ""
        
        if rule:
            self.pattern_scores[rule] = self.pattern_scores.get(rule, 0.0) + 1.0
        
        if lesson:
            # êµí›ˆì„ ì§€í˜œ ë² ì´ìŠ¤ì— ì¶”ê°€
            self.wisdom_base.append({
                "lesson": lesson,
                "source_id": res.get("id"),
                "timestamp": datetime.utcnow().isoformat() + "Z",
                "score": 1.0
            })
            # ì§€í˜œ ë² ì´ìŠ¤ í¬ê¸° ì œí•œ (ìµœê·¼ 100ê°œ)
            if len(self.wisdom_base) > 100:
                self.wisdom_base = self.wisdom_base[-100:]
        
        return {"status": "grown", "saved": res, "lesson_added": bool(lesson)}

    async def self_reflection(self) -> Dict[str, Any]:
        """ìê¸° ì„±ì°° - êµí›ˆ í†µí•© ë° íŒ¨í„´ ë¶„ì„"""
        merged = 0  # placeholder for future merge logic
        self.last_reflection = datetime.utcnow()
        
        # ìƒìœ„ êµí›ˆ ì¶”ì¶œ
        top_lessons = []
        if self.wisdom_base:
            # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
            sorted_wisdom = sorted(self.wisdom_base, key=lambda x: x.get("score", 0), reverse=True)
            top_lessons = [w["lesson"] for w in sorted_wisdom[:5]]
        
        # ìƒìœ„ íŒ¨í„´ ì¶”ì¶œ
        top_patterns = dict(sorted(self.pattern_scores.items(), key=lambda x: -x[1])[:10])
        
        return {
            "merged": merged,
            "pattern_scores": self.pattern_scores,
            "top_patterns": top_patterns,
            "top_lessons": top_lessons,
            "wisdom_count": len(self.wisdom_base),
            "last_reflection": self.last_reflection.isoformat() + "Z",
        }
